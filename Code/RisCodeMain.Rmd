---
title: "Laboratorio didattico"
subtitle: "The Psychological Burden of the COVID-19"
author: Corrado Caudek
date: "19-05-2022"
output:
  html_document:
    highlight: pygments
    fig_caption: yes
    toc: TRUE
    toc_depth: 2
    number_sections: TRUE
    toc_float:
      smooth_scroll: FALSE
---
<h1>Premesse generali</h1>
<p>1.Durante lo svolgimento dei vari report, per consentire una migliore comunicazione e fruibilita' del materiale da noi prodotto abbiamo usufruito dello strumento GitKraken, ovvero un software che ci consentiva di avere, ognuno sulla propria macchina, il progetto condiviso da tutti senza doverci incontrare fisicamente. <br>
2.Abbiamo suddiviso il lavoro fra noi tenendo di conto dei punti di forza di ciascuno, in modo da valorizzare più aspetti possibili del progetto</p>



<h1>In cosa consiste la ricerca </h1>
<p>I ricercatori si sono interessati alle possibili associazioni che possono intercorrere tra il carico psicologico dato dal COVID-19 e i seguenti fenomeni: gli atteggiamenti anti sistemici, quali l’insoddisfazione con l’ordine politico e la struttura sociale, l’attivismo politico pacifico e la violenza politica.<br>
I campioni sono adulti provenienti da USA, Italia, Danimarca e Ungheria.<br>
Infine, i dati sulle sue ondate sono stati raccolti attraverso sondaggi somministrati online. </p>



<h1>Cosa andremo a fare   </h1>
<p> Il  nostro lavoro si concentrera’ maggiormente sulla prima ipotesi. Difatti, andremo a sottrarre dalla totalità dei dati quanto i cittadini delle quattro nazioni concordano o meno con le misure adottate dai governi contro il COVID-19, durante le due ondate. Tali “atteggiamenti” sono stati misurati tramite una scala Likert che comprende valori da 0 (fortemente in disaccordo) a 6 (fortemente d’accordo). <br>
descrizione che faremo una beta-binomiale… <br>
Ciononostante, la nostra priori non comprenderà tutti i punteggi ricavati, ma solo parte di essi. Infatti, attraverso il comando R ifelse() andremo a determinare gli insuccessi e i successi. y saranno quei valori > numero a caso , mentre i restanti verranno considerati insuccessi.  <br>
Nel nostro caso verrà utilizzata una distribuzione a priori uniforme (Beta di parametri alpha = ? e beta = ?) – debolmente informativa/informativa?  <br>
“Dopodichè andremo a calcolare la media della distribuzione a posteriori per la probabilità di ottenere delle risposte che superino il livello X della scala Likert”.
</p>


<p>Carico i pacchetti necessari</p>
```{r}
suppressPackageStartupMessages({
  library("tidyverse")
  library("here")
  library("rio")
  library("brms")
  library("psych")
  library("cmdstanr")
})
```

<p>Lettura dei dati</p>
```{r}
df <- rio::import(here::here("DatiR", "hope_violence_final.dta"))
```

Per capire a cosa corrisponda la codifica di `country` conto il numero di casi in ciascun paese e in ciascuna wave. 

```{r}
table(df$wave, df$country)
```

Confrontando le frequenze ottenute con i dati riportati dagi autori concludo che la codifica è la seguente:

- 1: USA; 
- 2: Denmark; 
- 3: Italy; 
- 4: Hungary.

# Need for Chaos Scale

Gli autori riportano che gli item della scala Need for Chaos Scale (NFC) corrispondono alle colonne da Q27_1 a Q27_8. Seleziono dunque queste colonne dal dataframe:

```{r}
nfc_items <- df %>%
   select(
     starts_with("Q27_")
    ) 
```

```{r}
nfc <- rowSums(nfc_items) 
hist(nfc)
```
Questa codifica non ha senso, dato che ci aspettiamo che solo pochi partecipanti abbiano valori estremi e alti su questa scala. La media di NFC, infatti, non corrisponde a quello che riportano gli autori:

```{r}
mean(nfc / 8)
```

Quindi, la codifica deve essere invertita. Per fare questo uso la funzione `reverse.code()` del pacchetto `psych`:

```{r}
keys <- rep(-1, 8)  #reverse all items
nfc_items_r <- reverse.code(keys, nfc_items, mini=rep(1, 8), maxi=rep(7, 8))
nfc_items[1:3, ]
nfc_items_r[1:3, ]
```

Per calcolare il punteggio totale, sommo il valore degli item e divido per il numero di item (punteggio medio).

```{r}
nfc <- rowSums(nfc_items_r) 
hist(nfc)
```

Dato che gli autori usano la media, divido per 8

```{r}
nfc <- rowSums(nfc_items_r) / 8
hist(nfc)
summary(nfc)
```

Dato che gli autori usano la gamma 0--7

```{r}
summary(nfc)
```

sottraggo 1:

```{r}
nfc <- (rowSums(nfc_items_r) / 8) - 1
hist(nfc)
```

```{r}
summary(nfc)
```

I dati di wave 2 corrispondono a quelli riportati dagli autori nel materiale supplementare a p. 8: 

```{r}
df$nfc <- nfc

df %>% 
  group_by(wave) %>% 
  summarise(
    avg_nfc = mean(nfc),
    sd_nfc = sd(nfc),
    n = n()
  )
```

Mi occuperò dopo di eliminare i soggetti di wave 1 che non sono presenti in wave 2. 

zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz zzz

# Perceived COVID-19 burden scale

Gli autori riportano che gli item della scala Perceived COVID-19 burden scale (PCBS10) corrispondono alle colonne da Q7_1 a Q7_10. Seleziono queste colonne dal dataframe:

```{r}
pcbs10_items <- df %>%
   select(
     starts_with("Q7_")
    ) 
```

Gli autori riportano:

> The answer options ranged from strongly agree = 0 to strongly disagree = 6. 

```{r}
summary(pcbs10_items)
```

Sottraggo dunque 1:

```{r}
pcbs10_items_1 <- pcbs10_items - 1
summary(pcbs10_items_1)
```

Gli autori affermano:

> R indicates items that were reverse-coded for the analyses, so that higher scores indicated higher COVID-19 burden.

Il reverse coding viene applicato agli item 2, 3, 5, 7, 9:

```{r}
keys <- c(1, -1, -1, 1, -1, 1, -1, 1, -1, 1)  #reverse -1 items
pcbs10_items_r <- reverse.code(
  keys, 
  pcbs10_items_1, 
  mini=rep(0, 10), 
  maxi=rep(6, 10)
)
pcbs10_items_1[1:3, ]
pcbs10_items_r[1:3, ]
```

Adesso calcolo il punteggio totale:

```{r}
df$pcbs10 <- rowSums(pcbs10_items_r) / 10 
hist(df$pcbs10)
```

I dati per wave 2 corrispondono a quelli indicati dagli autori:

```{r}
df %>% 
  group_by(wave) %>% 
  summarise(
    avg_pcbs10 = mean(pcbs10),
    sd_pcbs10 = sd(pcbs10),
    min_pcbs10 = min(pcbs10),
    max_pcbs10 = max(pcbs10),
    n = n()
  )
```

Seleziono i dati di ciascuna wave:

```{r}
wave_1 <- df %>% 
  dplyr::filter(wave == 1)

wave_2 <- df %>% 
  dplyr::filter(wave == 2)

nrow(wave_1)
nrow(wave_2)
```

Estraggo solo le colonne di interesse:

```{r}
w1 <- wave_1 %>% 
  dplyr::select(id, nfc, pcbs10)
w2 <- wave_2 %>% 
  dplyr::select(id, nfc, pcbs10)
```

Unisco i dati considerando solo le righe in cui ID è presente in ciascuna wave:

```{r}
dat <- left_join(w2, w1, by = "id")
```

```{r}
y_tot<-c(dat$nfc.y,dat$pcbs10.y)
group_tot <- c(rep(0, length(dat$nfc.y)), rep(1, length(dat$pcbs10.y)))
d <- tibble(y_tot, group_tot)

data_list <- list( N = (length(dat$id)*2), x = d$group_tot, y = d$y_tot)

file <- file.path("modello_report.stan")
mod <- cmdstan_model(file)

#prova di un esercizio con modello dstan3 modello non ben identificato

fit <- mod$sample( data = data_list, iter_sampling = 100000L, iter_warmup = 50000L, chains = 4L, refresh = 0)

fit_stanfit <- rstan::read_stan_csv(fit$output_files())

fit$summary()
```
<p>il valore atteso di coehn_d (1.27) significa che all'aumentare di un'unita' sulla scala nfc corrisponde un aumento in media di tale valore sulla scala pcbs10</p>

<p>spostare le distribuzioni come parametri per inserirle nel file rmd cosi' da fornire una spiegazione sulla loro scelta debolmente informativa fatta da noi</p>



<h1>Confronto fra due medie</h1>
<p>TODO: inserire incipit iniziale breve</p>
<br>
<p>TODO: mostrare modello utilizzato con breve spiegazione del perche’ si e’ scelto</p>
<br>
<p>commento ipotetico sezione codice_1</p>
<br>
<p>commento ipotetico sezione codice_2</p>
<br>
<p>TODO: considerazioni finali, significato di cio’ che si e’ ottenuto</p>
<br>


<br>Il progetto e' stato svolto da:
<br>Virginia Simoncini
<br>William Tranchino
<br>Giulia Viliani
<br>Samanta Roncolino
<br>Regina Meister
<br>Lorenzo Zerauschek
<br>Alessia Nesti
<br>Martina Pierallini
<br>Greta Menichetti
<br>Elisa Pellegrini
<br>Chiara Manetti
<br>Elisa Placedi
<br>Flavia Natoli
<br>Costanza Lunari
<br>Marta Mariottini
<br>Gaia Lenzini
<br>Matteo Portici
<br>Camilla Pensalfini
<br>Leonardo Pecori
<br>Lorenza Paladini
<br>Eleonora Lunardi
<br>Serena Sooriya
<br>Isabella Scavone
<br>Alessia Massini
<br>Matilde Papini
<br>Martina Splendorini


  data {
    int<lower=0> N;
    vector[N] y;
    vector[N] x;
    real MU_A;
    real<lower=0> SIGMA_A;
    real MU_B;
    real<lower=0> SIGMA_B;
    real<lower=0> CSCALE;
  }
  parameters {
    real alpha;
    real beta;
    real<lower=0> sigma;
  }
  model {
    alpha ~ normal(MU_A, SIGMA_A);
    beta ~ normal(MU_B, SIGMA_B);
    sigma ~ cauchy(0, CSCALE);
    y ~ normal(alpha + beta * x, sigma);
  }
  generated quantities {
    real cohen_d;
    cohen_d = beta / sigma;
  }
